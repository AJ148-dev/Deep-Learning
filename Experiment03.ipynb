{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPmMYWcDJkcMd45aJyJex8Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7At2mDsPhKA","executionInfo":{"status":"ok","timestamp":1771093247868,"user_tz":-330,"elapsed":46,"user":{"displayName":"23/CS/075 ARIHANTJAIN","userId":"04238664416050048523"}},"outputId":"e529a16a-e590-4df5-c19b-8bb61d428371"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Downloading https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip...\n","Failed to download. Status code: 403\n"]}],"source":["import os\n","import requests\n","import zipfile\n","import shutil\n","import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# --- 1. CLEAN UP PREVIOUS ATTEMPTS ---\n","if os.path.exists('cats_and_dogs_filtered.zip'):\n","    os.remove('cats_and_dogs_filtered.zip')\n","if os.path.exists('cats_and_dogs_filtered'):\n","    shutil.rmtree('cats_and_dogs_filtered')\n","\n","# --- 2. DOWNLOAD WITH BROWSER HEADERS ---\n","url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n","dest = \"cats_and_dogs_filtered.zip\"\n","\n","print(f\"Downloading {url}...\")\n","\n","# This 'headers' part is the magic trick to bypass 403 errors\n","headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n","\n","response = requests.get(url, headers=headers, stream=True)\n","\n","if response.status_code == 200:\n","    with open(dest, 'wb') as f:\n","        for chunk in response.iter_content(chunk_size=8192):\n","            f.write(chunk)\n","    print(\"Download successful!\")\n","\n","    # --- 3. EXTRACT ---\n","    print(\"Extracting...\")\n","    with zipfile.ZipFile(dest, 'r') as zip_ref:\n","        zip_ref.extractall('.')\n","    print(\"Dataset ready.\")\n","else:\n","    print(f\"Failed to download. Status code: {response.status_code}\")"]},{"cell_type":"code","source":["# --- CIFAR-10 Loading ---\n","transform_cifar = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","print(\"Loading CIFAR-10...\")\n","train_cifar = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n","test_cifar = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n","\n","train_loader_cifar = DataLoader(train_cifar, batch_size=64, shuffle=True)\n","test_loader_cifar = DataLoader(test_cifar, batch_size=64, shuffle=False)\n","\n","# --- Cats vs Dogs Loading ---\n","transform_dogs = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# The extracted folder is 'cats_and_dogs_filtered/train'\n","train_dir = './cats_and_dogs_filtered/train'\n","\n","if os.path.exists(train_dir):\n","    print(\"Loading Cats vs Dogs...\")\n","    full_dataset = datasets.ImageFolder(root=train_dir, transform=transform_dogs)\n","\n","    # Split 80% Train, 20% Test\n","    train_size = int(0.8 * len(full_dataset))\n","    test_size = len(full_dataset) - train_size\n","    train_dogs, test_dogs = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n","\n","    train_loader_dogs = DataLoader(train_dogs, batch_size=32, shuffle=True)\n","    test_loader_dogs = DataLoader(test_dogs, batch_size=32, shuffle=False)\n","    print(\"Cats vs Dogs loaded successfully.\")\n","else:\n","    print(\"Error: Dataset folder not found. Check Step 1.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPfKL0gHPimQ","executionInfo":{"status":"ok","timestamp":1771093249449,"user_tz":-330,"elapsed":1570,"user":{"displayName":"23/CS/075 ARIHANTJAIN","userId":"04238664416050048523"}},"outputId":"12842bcc-678b-4a2e-b0de-79c723e180ef"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading CIFAR-10...\n","Error: Dataset folder not found. Check Step 1.\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import itertools\n","import copy\n","\n","class CustomCNN(nn.Module):\n","    def __init__(self, num_classes, activation=\"relu\"):\n","        super(CustomCNN, self).__init__()\n","\n","        if activation == \"relu\":\n","            self.act = nn.ReLU()\n","        elif activation == \"tanh\":\n","            self.act = nn.Tanh()\n","        elif activation == \"leaky\":\n","            self.act = nn.LeakyReLU(0.01)\n","\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            self.act,\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            self.act,\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            self.act,\n","            nn.MaxPool2d(2, 2)\n","        )\n","\n","        if num_classes == 10:\n","            self.flatten_dim = 128 * 8 * 8\n","        else:\n","            self.flatten_dim = 128 * 16 * 16\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(self.flatten_dim, 256),\n","            self.act,\n","            nn.Dropout(0.5),\n","            nn.Linear(256, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.classifier(x)\n","        return x\n","\n","def init_weights(model, init_type):\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.Linear)):\n","            if init_type == \"xavier\":\n","                nn.init.xavier_uniform_(m.weight)\n","            elif init_type == \"kaiming\":\n","                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n","            elif init_type == \"random\":\n","                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n","\n","def train_epoch(model, loader, criterion, optimizer):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    return running_loss / len(loader), correct / total\n","\n","def eval_model(model, loader, criterion):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return correct / total"],"metadata":{"id":"v7M0uLL5Rfe1","executionInfo":{"status":"ok","timestamp":1771093249478,"user_tz":-330,"elapsed":12,"user":{"displayName":"23/CS/075 ARIHANTJAIN","userId":"04238664416050048523"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def run_full_experiment(dataset_name, train_loader, test_loader, num_classes):\n","    print(f\"\\n STARTING EXPERIMENT: {dataset_name}\\n\")\n","\n","    activations = [\"relu\", \"tanh\", \"leaky\"]\n","    inits = [\"xavier\", \"kaiming\", \"random\"]\n","    optimizers_list = [\"sgd\", \"adam\", \"rmsprop\"]\n","\n","    best_acc = 0.0\n","    best_config = \"\"\n","    best_model_wts = None\n","\n","    criterion = nn.CrossEntropyLoss()\n","\n","\n","    for act, init, opt in itertools.product(activations, inits, optimizers_list):\n","        print(f\"Testing Config: Act={act} | Init={init} | Opt={opt}\")\n","\n","        model = CustomCNN(num_classes=num_classes, activation=act).to(device)\n","        init_weights(model, init)\n","\n","        if opt == \"sgd\":\n","            optimizer = optim.SGD(model.parameters(), lr=0.01)\n","        elif opt == \"adam\":\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","        else:\n","            optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n","\n","        for epoch in range(1):\n","            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n","            val_acc = eval_model(model, test_loader, criterion)\n","\n","        print(f\"  -> Final Validation Acc: {val_acc:.4f}\")\n","\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            best_config = f\"{act}_{init}_{opt}\"\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    print(f\"\\n*** BEST CUSTOM MODEL: {best_config} (Acc: {best_acc:.4f}) ***\")\n","\n","    torch.save(best_model_wts, f'best_cnn_{dataset_name.replace(\" \", \"\")}.pth')\n","\n","    print(f\"\\n--- Running ResNet-18 Transfer Learning on {dataset_name} ---\")\n","    resnet = torchvision.models.resnet18(pretrained=True)\n","\n","\n","    for param in resnet.parameters():\n","        param.requires_grad = False\n","\n","    num_ftrs = resnet.fc.in_features\n","    resnet.fc = nn.Linear(num_ftrs, num_classes)\n","    resnet = resnet.to(device)\n","\n","    res_optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n","\n","    for epoch in range(1):\n","        _, _ = train_epoch(resnet, train_loader, criterion, res_optimizer)\n","        res_acc = eval_model(resnet, test_loader, criterion)\n","        print(f\"  ResNet Epoch {epoch+1} Acc: {res_acc:.4f}\")\n","\n","    print(f\"\\nFINAL COMPARISON ({dataset_name}):\")\n","    print(f\"Custom CNN Best: {best_acc:.4f}\")\n","    print(f\"ResNet-18:       {res_acc:.4f}\")\n","\n","run_full_experiment(\"CIFAR-10\", train_loader_cifar, test_loader_cifar, 10)\n","\n","if 'train_loader_dogs' in globals():\n","    run_full_experiment(\"Cats vs Dogs\", train_loader_dogs, test_loader_dogs, 2)\n","else:\n","    print(\"Skipping Cats vs Dogs (Loader not found).\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6uCQYlKdRyFK","executionInfo":{"status":"ok","timestamp":1771094146625,"user_tz":-330,"elapsed":897142,"user":{"displayName":"23/CS/075 ARIHANTJAIN","userId":"04238664416050048523"}},"outputId":"a35dba81-f139-4f0b-fcee-4bf42546205d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," STARTING EXPERIMENT: CIFAR-10\n","\n","Testing Config: Act=relu | Init=xavier | Opt=sgd\n","  -> Final Validation Acc: 0.5031\n","Testing Config: Act=relu | Init=xavier | Opt=adam\n","  -> Final Validation Acc: 0.4429\n","Testing Config: Act=relu | Init=xavier | Opt=rmsprop\n","  -> Final Validation Acc: 0.3639\n","Testing Config: Act=relu | Init=kaiming | Opt=sgd\n","  -> Final Validation Acc: 0.4976\n","Testing Config: Act=relu | Init=kaiming | Opt=adam\n","  -> Final Validation Acc: 0.3896\n","Testing Config: Act=relu | Init=kaiming | Opt=rmsprop\n","  -> Final Validation Acc: 0.3827\n","Testing Config: Act=relu | Init=random | Opt=sgd\n","  -> Final Validation Acc: 0.5131\n","Testing Config: Act=relu | Init=random | Opt=adam\n","  -> Final Validation Acc: 0.5392\n","Testing Config: Act=relu | Init=random | Opt=rmsprop\n","  -> Final Validation Acc: 0.4799\n","Testing Config: Act=tanh | Init=xavier | Opt=sgd\n","  -> Final Validation Acc: 0.5009\n","Testing Config: Act=tanh | Init=xavier | Opt=adam\n","  -> Final Validation Acc: 0.4978\n","Testing Config: Act=tanh | Init=xavier | Opt=rmsprop\n","  -> Final Validation Acc: 0.2797\n","Testing Config: Act=tanh | Init=kaiming | Opt=sgd\n","  -> Final Validation Acc: 0.5014\n","Testing Config: Act=tanh | Init=kaiming | Opt=adam\n","  -> Final Validation Acc: 0.5100\n","Testing Config: Act=tanh | Init=kaiming | Opt=rmsprop\n","  -> Final Validation Acc: 0.4492\n","Testing Config: Act=tanh | Init=random | Opt=sgd\n","  -> Final Validation Acc: 0.3563\n","Testing Config: Act=tanh | Init=random | Opt=adam\n","  -> Final Validation Acc: 0.4908\n","Testing Config: Act=tanh | Init=random | Opt=rmsprop\n","  -> Final Validation Acc: 0.4688\n","Testing Config: Act=leaky | Init=xavier | Opt=sgd\n","  -> Final Validation Acc: 0.4843\n","Testing Config: Act=leaky | Init=xavier | Opt=adam\n","  -> Final Validation Acc: 0.4820\n","Testing Config: Act=leaky | Init=xavier | Opt=rmsprop\n","  -> Final Validation Acc: 0.4765\n","Testing Config: Act=leaky | Init=kaiming | Opt=sgd\n","  -> Final Validation Acc: 0.5155\n","Testing Config: Act=leaky | Init=kaiming | Opt=adam\n","  -> Final Validation Acc: 0.5129\n","Testing Config: Act=leaky | Init=kaiming | Opt=rmsprop\n","  -> Final Validation Acc: 0.4664\n","Testing Config: Act=leaky | Init=random | Opt=sgd\n","  -> Final Validation Acc: 0.5441\n","Testing Config: Act=leaky | Init=random | Opt=adam\n","  -> Final Validation Acc: 0.5650\n","Testing Config: Act=leaky | Init=random | Opt=rmsprop\n","  -> Final Validation Acc: 0.4698\n","\n","*** BEST CUSTOM MODEL: leaky_random_adam (Acc: 0.5650) ***\n","\n","--- Running ResNet-18 Transfer Learning on CIFAR-10 ---\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 186MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["  ResNet Epoch 1 Acc: 0.6276\n","\n","FINAL COMPARISON (CIFAR-10):\n","Custom CNN Best: 0.5650\n","ResNet-18:       0.6276\n","Skipping Cats vs Dogs (Loader not found).\n"]}]}]}