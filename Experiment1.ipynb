{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOVSx/Fk1VAKTXRpKU6rdg8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","**Experiment-01**\n","---\n","\n"],"metadata":{"id":"Yn0acL4P48O3"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"98etmdBT4mKA","executionInfo":{"status":"ok","timestamp":1769276246210,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}}},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","source":["###Create 1 D,2D and 3D tensors using Pytorch and Numpy."],"metadata":{"id":"0rhyfXLu5ct4"}},{"cell_type":"code","source":["np_1d = np.array([1, 2, 3])\n","pt_1d = torch.tensor([1, 2, 3])\n","\n","print(f\"PyTorch 1D: {pt_1d}\")\n","print(f\"NumPy 1D: {np_1d}\")\n","\n","print(f\"PyTorch 1D Shape: {pt_1d.shape}\")\n","print(f\"NumPy 1D Shape: {np_1d.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wA9glD1X5cVU","executionInfo":{"status":"ok","timestamp":1769276246275,"user_tz":-330,"elapsed":62,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"6812bda2-9e70-40c8-b585-58fedde1fa27"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch 1D: tensor([1, 2, 3])\n","NumPy 1D: [1 2 3]\n","PyTorch 1D Shape: torch.Size([3])\n","NumPy 1D Shape: (3,)\n"]}]},{"cell_type":"code","source":["np_2d = np.array([[1, 2, 3], [4, 5, 6]])\n","pt_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","\n","print(f\"PyTorch 2D: {pt_2d}\")\n","print(f\"NumPy 2D: {np_2d}\")\n","\n","print(f\"PyTorch 2D Shape: {pt_2d.shape}\")\n","print(f\"NumPy 2D Shape: {np_2d.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcEY75mY6Y-0","executionInfo":{"status":"ok","timestamp":1769276246279,"user_tz":-330,"elapsed":3,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"39f4e04e-f9cc-45d8-b3da-5dd095c60805"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch 2D: tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","NumPy 2D: [[1 2 3]\n"," [4 5 6]]\n","PyTorch 2D Shape: torch.Size([2, 3])\n","NumPy 2D Shape: (2, 3)\n"]}]},{"cell_type":"code","source":["np_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n","pt_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n","\n","print(f\"PyTorch 3D: {pt_3d}\")\n","print(f\"NumPy 3D: {np_3d}\")\n","\n","print(f\"PyTorch 3D Shape: {pt_3d.shape}\")\n","print(f\"NumPy 3D Shape: {np_3d.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEtGse6T6cNl","executionInfo":{"status":"ok","timestamp":1769276246295,"user_tz":-330,"elapsed":15,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"35eb4231-fccc-43c4-e5ff-54048f2fd0a3"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch 3D: tensor([[[1, 2],\n","         [3, 4]],\n","\n","        [[5, 6],\n","         [7, 8]]])\n","NumPy 3D: [[[1 2]\n","  [3 4]]\n","\n"," [[5 6]\n","  [7 8]]]\n","PyTorch 3D Shape: torch.Size([2, 2, 2])\n","NumPy 3D Shape: (2, 2, 2)\n"]}]},{"cell_type":"markdown","source":["###Show basic operations: Element wise Operations"],"metadata":{"id":"OB8gAK1b6nXk"}},{"cell_type":"code","source":["x = torch.tensor([10, 20, 30])\n","y = torch.tensor([1, 2, 3])\n","\n","# Addition\n","print(x + y)\n","print(torch.add(x, y))\n","\n","# Subtraction\n","print(x - y)\n","print(torch.sub(x, y))\n","\n","# Multiplication\n","print(x * y)\n","\n","# Division\n","print(x / y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bb7fRvh86mzN","executionInfo":{"status":"ok","timestamp":1769276246297,"user_tz":-330,"elapsed":1,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"c2e855e4-c423-48f9-e970-8c64bf865b82"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([11, 22, 33])\n","tensor([11, 22, 33])\n","tensor([ 9, 18, 27])\n","tensor([ 9, 18, 27])\n","tensor([10, 40, 90])\n","tensor([10., 10., 10.])\n"]}]},{"cell_type":"markdown","source":["###Indexing and slicing operations( Boolean Masking, extracting subtensor.. etc)"],"metadata":{"id":"DmL6BwXU7XHS"}},{"cell_type":"code","source":["t = torch.tensor([[1, 2, 3],\n","                  [4, 5, 6],\n","                  [7, 8, 9]])\n","\n","print(t[0, :])\n","print(t[:, -1])\n","\n","# Extract a 2x2 sub-tensor\n","sub_t = t[:2, :2]\n","print(sub_t)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KM8GfRAe7JCt","executionInfo":{"status":"ok","timestamp":1769276246301,"user_tz":-330,"elapsed":3,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"b259c152-886f-4d32-9773-857b88f309c3"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3])\n","tensor([3, 6, 9])\n","tensor([[1, 2],\n","        [4, 5]])\n"]}]},{"cell_type":"code","source":["#Boolean masking\n","data = torch.tensor([10, 25, 3, 45, 2])\n","\n","mask = data > 20\n","print(mask)\n","\n","filtered = data[mask]\n","print(filtered)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ej4l13kM7vCl","executionInfo":{"status":"ok","timestamp":1769276246309,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"930991c5-1843-43aa-9d91-67025539247d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([False,  True, False,  True, False])\n","tensor([25, 45])\n"]}]},{"cell_type":"markdown","source":["###.view, .reshape .unsqueeze and squeeze function in pytorch"],"metadata":{"id":"6MvnYbX48Dk4"}},{"cell_type":"markdown","source":["1. **.view():** Returns a new tensor with the same data as the self tensor but different shape. It requires the data to be contiguous in memory. It is faster because it strictly avoids data copying.\n","\n","2. **.reshape():** Returns a tensor with the same data and number of elements as self but with the specified shape. Unlike .view(), reshape() can handle non-contiguous tensors by creating a copy if necessary. If the tensor is contiguous, it behaves like .view().\n","\n","3. **.unsqueeze():** Returns a new tensor with a dimension of size one inserted at the specified position (dim). This increases the number of dimensions of the tensor.\n","\n","4. **squeeze():** Returns a new tensor with all the dimensions of size 1 removed. If a dim argument is provided, only dimensions of size 1 at that specific position are removed."],"metadata":{"id":"iqwuRhxU8Pd0"}},{"cell_type":"code","source":["x = torch.arange(12)\n","\n","x_view = x.view(3, 4)\n","x_reshape = x.reshape(3, 4)\n","print(x_view)\n","print(x_reshape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LnIURDij8Ajc","executionInfo":{"status":"ok","timestamp":1769276246330,"user_tz":-330,"elapsed":21,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"188d0285-9519-4326-9234-1aba0e28967b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0,  1,  2,  3],\n","        [ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11]])\n","tensor([[ 0,  1,  2,  3],\n","        [ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11]])\n"]}]},{"cell_type":"code","source":["x = torch.zeros(2, 5) # Shape: (2, 5)\n","\n","# Unsqueeze: Add a dimension at index 0\n","x_unsqueezed = x.unsqueeze(0)\n","print(x_unsqueezed.shape)\n","\n","# Squeeze: Remove all dimensions of size 1\n","x_squeezed = x_unsqueezed.squeeze()\n","print(x_squeezed.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjtOqZ3A9hz2","executionInfo":{"status":"ok","timestamp":1769276246338,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"bb75dfcd-c0da-4a83-db33-f2fe6ed3c4b3"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2, 5])\n","torch.Size([2, 5])\n"]}]},{"cell_type":"markdown","source":["Comparison with NumPy\n","\n","NumPy uses .reshape() which works similarly to PyTorch's .reshape(). NumPy does not have .view() in the same sense; it relies on .reshape() to handle views vs copies automatically."],"metadata":{"id":"mZQz714UEboX"}},{"cell_type":"markdown","source":["###Broadcasting\n","\n","Broadcasting is the mechanism that allows PyTorch/NumPy to perform operations on tensors of different shapes. The smaller tensor is \"broadcast\" (stretched) across the larger tensor so they have compatible shapes.\n","\n","The Rules of Broadcasting:\n","\n","Align shapes from the last dimension backwards.\n","\n","Dimensions are compatible if they are equal, or if one of them is 1."],"metadata":{"id":"geQPDZs8ElqL"}},{"cell_type":"code","source":["A = torch.tensor([[1],\n","                  [2],\n","                  [3]])\n","\n","B = torch.tensor([4, 5, 6])\n","\n","# Result: Shape (3, 3)\n","# A becomes [[1,1,1], [2,2,2], [3,3,3]]\n","# B becomes [[4,5,6], [4,5,6], [4,5,6]]\n","C = A + B\n","\n","print(C)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fano-7-iEoeW","executionInfo":{"status":"ok","timestamp":1769276246346,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"ad13c61b-77a2-45bf-d25b-519c2916fcd5"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[5, 6, 7],\n","        [6, 7, 8],\n","        [7, 8, 9]])\n"]}]},{"cell_type":"markdown","source":["###In-place vs. Out-of-place Operations\n","\n","**Out-of-place:** Creates a new tensor in memory. The original tensor remains unchanged.\n","\n","**In-place:** Modifies the data of the original tensor directly. This saves memory but can cause issues with PyTorch's autograd (gradient calculation).\n","\n","In PyTorch, in-place operations are usually suffixed with an underscore _."],"metadata":{"id":"lGy4nXmAE5TY"}},{"cell_type":"code","source":["t = torch.tensor([1, 2, 3])\n","\n","new_t = t.add(10)\n","print(t)\n","print(new_t)  #\n","\n","# In-place\n","t.add_(10)\n","print(t)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrUqZquxDllJ","executionInfo":{"status":"ok","timestamp":1769276246354,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}},"outputId":"d6f31d67-5739-4d6c-cf90-5bb7b2369a3e"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3])\n","tensor([11, 12, 13])\n","tensor([11, 12, 13])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TG3HSYKNFPHI","executionInfo":{"status":"ok","timestamp":1769276246469,"user_tz":-330,"elapsed":1,"user":{"displayName":"Arihant Jain","userId":"09581354661724906835"}}},"execution_count":27,"outputs":[]}]}